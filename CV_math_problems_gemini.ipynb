{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vUWO8eaw_le0"
      },
      "outputs": [],
      "source": [
        "import cvzone\n",
        "import cv2\n",
        "from cvzone.HandTrackingModule import HandDetector\n",
        "import numpy as np\n",
        "import google.generativeai as genai\n",
        "from PIL import Image\n",
        "import streamlit as st"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "st.set_page_config(layout=\"wide\")\n",
        "st.image('MathGestures.png')\n"
      ],
      "metadata": {
        "id": "d4YOQcR3DRrq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "col1, col2 = st.columns([3,2])\n",
        "with col1:\n",
        "    run = st.checkbox('Run', value=True)\n",
        "    FRAME_WINDOW = st.image([])\n",
        "\n",
        "with col2:\n",
        "    st.title(\"Answer\")\n",
        "    output_text_area = st.subheader(\"\")"
      ],
      "metadata": {
        "id": "3JR4pv9LDWyx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "genai.configure(api_key=\"your api key\")\n"
      ],
      "metadata": {
        "id": "csTZ3xx6Danh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# list of models we can use\n",
        "for m in genai.list_models():\n",
        "  if \"generateContent\" in m.supported_generation_methods:\n",
        "    print(m.name)\n"
      ],
      "metadata": {
        "id": "XGJOfWabDcyH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# we can choose from a bunch of models provided by Gemini.ai\n",
        "model = genai.GenerativeModel('gemini-1.5-flash')\n"
      ],
      "metadata": {
        "id": "7ghWlpnADek5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the webcam to capture video\n",
        "# The '2' indicates the third camera connected to your computer; '0' would usually refer to the built-in camera\n",
        "cap = cv2.VideoCapture(1)\n",
        "cap.set(3,1280)\n",
        "cap.set(4,720)"
      ],
      "metadata": {
        "id": "ExPZLPJpDr2A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the HandDetector class with the given parameters\n",
        "detector = HandDetector(staticMode=False, maxHands=1, modelComplexity=1, detectionCon=0.7, minTrackCon=0.5)\n",
        ""
      ],
      "metadata": {
        "id": "Sb0Wi0KZDtoI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def getHandInfo(img):\n",
        "    # Find hands in the current frame\n",
        "    # The 'draw' parameter draws landmarks and hand outlines on the image if set to True\n",
        "    # The 'flipType' parameter flips the image, making it easier for some detections\n",
        "    hands, img = detector.findHands(img, draw=False, flipType=True)\n",
        "\n",
        "    # Check if any hands are detected\n",
        "    if hands:\n",
        "        # Information for the first hand detected\n",
        "        hand = hands[0]  # Get the first hand detected\n",
        "        lmList = hand[\"lmList\"]  # List of 21 landmarks for the first hand\n",
        "        # Count the number of fingers up for the first hand\n",
        "        fingers = detector.fingersUp(hand)\n",
        "        print(fingers)\n",
        "        return fingers, lmList\n",
        "    else:\n",
        "        return None"
      ],
      "metadata": {
        "id": "bklIeZ1PEFF6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def draw(info,prev_pos,canvas):\n",
        "    fingers, lmList = info\n",
        "    current_pos= None\n",
        "    if fingers == [0, 1, 0, 0, 0]:\n",
        "        current_pos = lmList[8][0:2]\n",
        "        if prev_pos is None: prev_pos = current_pos\n",
        "        cv2.line(canvas,current_pos,prev_pos,(255,0,255),10)\n",
        "    elif fingers == [1, 0, 0, 0, 0]:\n",
        "        canvas = np.zeros_like(img)\n",
        "\n",
        "    return current_pos, canvas"
      ],
      "metadata": {
        "id": "UP0G04zzEGwJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prev_pos= None\n",
        "canvas=None\n",
        "image_combined = None\n",
        "output_text= \"\"\n",
        "# Continuously get frames from the webcam\n",
        "while True:\n",
        "    # Capture each frame from the webcam\n",
        "    # 'success' will be True if the frame is successfully captured, 'img' will contain the frame\n",
        "    success, img = cap.read()\n",
        "    img = cv2.flip(img, 1)\n",
        "\n",
        "    if canvas is None:\n",
        "        canvas = np.zeros_like(img)\n",
        "\n",
        "\n",
        "    info = getHandInfo(img)\n",
        "    if info:\n",
        "        fingers, lmList = info\n",
        "        prev_pos,canvas = draw(info, prev_pos,canvas)\n",
        "        output_text = sendToAI(model,canvas,fingers)\n",
        "\n",
        "    image_combined= cv2.addWeighted(img,0.7,canvas,0.3,0)\n",
        "    FRAME_WINDOW.image(image_combined,channels=\"BGR\")\n",
        "\n",
        "    if output_text:\n",
        "        output_text_area.text(output_text)\n",
        "\n",
        "    # # Display the image in a window\n",
        "    # cv2.imshow(\"Image\", img)\n",
        "    # cv2.imshow(\"Canvas\", canvas)\n",
        "    # cv2.imshow(\"image_combined\", image_combined)\n",
        "\n",
        "\n",
        "    # Keep the window open and update it for each frame; wait for 1 millisecond between frames\n",
        "    cv2.waitKey(1)"
      ],
      "metadata": {
        "id": "yF0C5zEPEISM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}